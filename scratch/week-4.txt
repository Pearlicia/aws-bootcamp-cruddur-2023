# Create rds postgres db via aws clickops

aws rds create-db-instance \
  --db-instance-identifier cruddur-db-instance \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --engine-version  14.6 \
  --master-username root \
  --master-user-password huEE33z2Qvl383 \
  --allocated-storage 20 \
  --availability-zone us-east-1a \
  --backup-retention-period 0 \
  --port 5432 \
  --no-multi-az \
  --db-name cruddur \
  --storage-type gp2 \
  --publicly-accessible \
  --storage-encrypted \
  --enable-performance-insights \
  --performance-insights-retention-period 7 \
  --no-deletion-protection

  # Add time zone and character set

  # After db creation connect to it from terminal using psql

  psql -U postgres --host localhost

  # --host because of docker when not using docker no need for --host or -h

  # Common PSQL commands:

\x on -- expanded display when looking at data
\q -- Quit PSQL
\l -- List all databases
\c database_name -- Connect to a specific database
\dt -- List all tables in the current database
\d table_name -- Describe a specific table
\du -- List all users and their roles
\dn -- List all schemas in the current database
CREATE DATABASE database_name; -- Create a new database
DROP DATABASE database_name; -- Delete a database
CREATE TABLE table_name (column1 datatype1, column2 datatype2, ...); -- Create a new table
DROP TABLE table_name; -- Delete a table
SELECT column1, column2, ... FROM table_name WHERE condition; -- Select data from a table
INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...); -- Insert data into a table
UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE condition; -- Update data in a table
DELETE FROM table_name WHERE condition; -- Delete data from a table


# We can use the createdb command to create our database:
createdb cruddur -h localhost -U postgres

# We can create the database within the PSQL client
CREATE database cruddur;

# Delete database
DROP database cruddur;

# Import Script
# We'll create a new SQL file called schema.sql and we'll place it in backend-flask/db

# The command to import:

psql cruddur < db/schema.sql -h localhost -U postgres

Add UUID Extension
We are going to have Postgres generate out UUIDs. We'll need to use an extension called:

CREATE EXTENSION "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

# Add this to schema.sql file
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

# Then run this in terminal - cd to backend dir

psql cruddur < db/schema.sql -h localhost -U postgres

Password is password

# Connection String 
postgresql://postgres:pssword@127.0.0.1:5433/cruddur

# So to connect
psql postgresql://postgres:pssword@127.0.0.1:5433/cruddur

# Add to gitpod env
export CONNECTION_URL="postgresql://postgres:pssword@127.0.0.1:5433/cruddur"
gp env CONNECTION_URL="postgresql://postgres:pssword@127.0.0.1:5433/cruddur"

# Then 
psql $CONNECTION_URL

# PROD DB
export PROD_CONNECTION_URL="postgresql://cruddurroot:pssword@awspostgresendpoint:5433/cruddur"
gp env PROD_CONNECTION_URL="postgresql://cruddurroot:pssword@awspostgresendpoint:5433/cruddur"

# Then 
psql $PROD_CONNECTION_URL

# Create bin dir in backend then create bash files
# To run the bash files

ls -l ./bin      # to check if files have permissions
chmod u+x bin/db-create    # Add permissions to execute do it on all bin files

chmod +x bin/db-create    # Do this instead

./bin/db-drop or source /bin/db-drop

# Sed command
run man sed
sed - stream editor for filtering and transforming text
Sed  is  a stream editor.  A stream editor is used to perform basic text transformations on an input stream
(a file or input from a pipeline).  While in some ways

# Sessions script to see the running db processes run it to kill the processes

# lib/db.py
Add psycopg3 driver for connection, could use sqlalchemy orm instead

Connect to RDS via Gitpod
In order to connect to the RDS instance we need to provide our Gitpod IP and whitelist for inbound traffic on port 5432.

GITPOD_IP=$(curl ifconfig.me)
We'll create an inbound rule for Postgres (5432) and provide the GITPOD ID.

We'll get the security group rule id so we can easily modify it in the future from the terminal here in Gitpod.

export DB_SG_ID="sg-0b725ebab7e25635e"
gp env DB_SG_ID="sg-0b725ebab7e25635e"
export DB_SG_RULE_ID="sgr-070061bba156cfa88"
gp env DB_SG_RULE_ID="sgr-070061bba156cfa88"
Whenever we need to update our security groups we can do this for access.

aws ec2 modify-security-group-rules \
    --group-id $DB_SG_ID \
    --security-group-rules "SecurityGroupRuleId=$DB_SG_RULE_ID,SecurityGroupRule={IpProtocol=tcp,FromPort=5432,ToPort=5432,CidrIpv4=$GITPOD_IP/32}"
https://docs.aws.amazon.com/cli/latest/reference/ec2/modify-security-group-rules.html#examples










  
